***04/11/2021***

**Role Based Access Control** - системы доступа, основанная на ролях

__Состав:__
1) Role
2) RoleBinding
3) ClusterRole
4) ClusterRoleBinding
5) ServiceAccount

***Способы аутентификации***:
- Service Account,
- Использование стороннего сервера авторизации (протокол OIDC),
- Использование сертификатов (клиентских)

# Servive Account

Ответ на вопрос - кто пришел? \
В kubernetes нет пользователей в привычном понимании (логин, пароль, группа, метаинформация), ближайший аналог - `SA`. \

`ServiceAccount` задается __yaml-манифестом__, для него генерируется __JWT-токен__ (namespace, имя, когда/кем создан). При запросах к API передается токен (bearer), подписанный корневым сертификатом кластера. 

Когда создает контейнер, kubernetes добавляет туда служебную информацию для общения с API: \
- токен от SA, 
- имя namespace, 
- публичный корневой сертификат кластера.

Если SA не задан в манифесте пода - указывается SA default (всегда создается при создании namespace). \

***Связка***:
- с ролями (Roles) \
Объекты на уровне namespace. В случае, если SA должне иметь доступ к нескольким namespace - нужно сдедать несколько связок (binding) с ролями в разных namespace. 
- с кластерными ролями (ClusterRole) \
Все объекты на уровне кластера. \ 
Связать с несколькими namespaces по регулярному выражению в имени не получится.  

# Role

> Все объекты в kubernetes по версионированию можно разделить на 2 группы:
> - старые объекты, обращение к которым идет напрямую: __GET /api/v1/namespaces/{namespace}/pods/{name}/log__ \ 
> - новые объекты, объединенные в группу (в данном примере - apis/networking.k8s.io): __GET /apis/networking.k8s.io/v1beta1/namespaces/{namespace}/ingress__ \ 
>
> Объекты в etcd могуть добавлены любой версии и запросить их можно в любой, но храниться будут в определенной выбранной версии.

Описывает права на операции, которые могут быть выполнены с объектом, объекты принадлежат конкретному namespace (как и роль). 

Роль состоит из списка `Rules`.\
Состав правила:
- `apiGroups`: ["extensions", "networking.k8s.io"] / [""]; (несколько api групп в случае необходимости поддержать совместимость версий, пусто - для старых объектов)
- `resources`: ["ingress"] / ["pods", "pods/log"] 
- `verbs` ["get", "post" ... ] \
Иногда добавляется: `resourceName` - чтобы обратиться к конкретному ресурсу.
**Совокупность правил определяет все все возможные операции с ресурсами в рамках роли**

# RoleBinding

Объект, связыващий `Role` и `ServiceAccount`. Связана с namespace: описывают связки ролей, дающих доступ к объектам в конкретном namespace. 

Атрибуты манифеста:
- `roleRef` - ссылка на роль
- `subjects` - массив `SA` (namespace + name)

# ClusterRole / ClusterRoleBinding

Аналогично `Role`/`RoleBinding`, но для сущностей всего кластера. 

Есть __типовые кластерные роли__, которые можно добавлять в `RoleBinding`: в этом случае права применяются от кластерной роли, но сохраняется ограничение на namespace.\
Роли:
- __view__ - просматривать сущности,
- __edit__ - редактировать сущности (кроме секретов), 
- __admin__ - видеть и редактировать все сущности (в т.ч. секреты)
- __cluster-admin__ - видеть и управлять всеми сущностями кластера (самое короткое описание, используется `*` для verbs, apiGroups, resources)

# Дополнительные варианты аутентификации

1) __Сторонний сервер аутентификации__ (тот же gitlab, active directory, ldap)
В этом случае можно в манифесте `RoleBinding` состаться на пользователя (User) и группу (Group), которые ведутся на внешнем сервере аутентификации.

2) __Клиентские сертификаты__ 
Аналогично врнешнему серверу аутентификации, только User = CN, Group = Organization. Клиентский сертификат должен быть подписан доверенным сертификатом для kubenetes (обычно это __корневой сертификат kubernetes__)

***Best practice***:
- небольшие команды - SA,
- крупные компании - собственный сервер аутентификации,
- сертификаты - нет revoke-list, поэтому если конкретный сотрудник уволился и увел сертификат, то он может обращаться в кластер и дальше. 

# Practice

```bash
## получить SA
kubectl get sa 
# получить информацию о роли
kubectl get role -n <namespace> <name> -o yaml
# создать новые объекты (SA, RoleBinding, ConfigMap, Secret)
kubectl apply -f .
# получить расширенную информацию о SA (токен закодирован base64)
kubectl get secret user-token-sxzkg -o yaml
# получить расширенную информацию о SA (токен раскрыт)
kubectl describe secret user-token-sxzkg
# получить RoleBinding 
kubectl get rolebinding`
# получить лист configmap под конкретным пользователем (переопределяем в запросе)
kubectl get configmap --as=system:serviceaccount:s016497:user
# получить лист configmap во всех namespace под конкретным пользователем - недоступно (роль только для конкретного namespace)
kubectl get configmap --as=system:serviceaccount:s016497:user -A
# удалить configmap - недоступно (роль view)
kubectl delete configmap my-configmap-env --as=system:serviceaccount:s016497:user
# получить лист secret под конкретным пользователем (переопределяем в запросе) - нет доступа (роль view)
kubectl get secret --as=system:serviceaccount:s016497:user
```

# Kubectl config

Конфигурация kubectl: указывает доступные кластеры, пользователей и контекст, который связывает кластеры и пользователей.

``` bash
kubectl config
```
> apiVersion: v1
> clusters:
> - cluster: 
>    insecure-skip-tls-verify: true
>    server: https://5.188.142.58:6443
>  name: mcs.slurm.io
> contexts:
> - context:
>    cluster: mcs.slurm.io
>    namespace: s016497
>    user: s016497
>  name: mcs.slurm.io
> current-context: mcs.slurm.io    ### изменяется kubectl set-context
> kind: Config
> preferences: {}
> users:   
> - name: s016497
>  user:
>    token: REDACTED

Можно использовать утилиту ``k8sh``, которая имеет короткие команды __ctx__ и __ns__ для переключения между контекстами и namespace внутри контекста.

# Дополнительные способы ограничения доступов

## Ресурсная квота (Resource quotas): 
Ограничение ресурсов на namespace. 

``` bash
kubectl get resourcequotas <name> -o yaml
```

1. Количество ресурсов на проект: количество запросов на CPU и лимит памяти, если текущие поды превысили - следующий под не создается. 
2. Количество возможных сущностей kubernetes. 

Разделы: доступные ограничения, использованные ресурсы (used)

## Лимит ресурсов (Limit range)
Ограничение ресурсов на под. 

``` bash
kubectl get limitrange <name> -o yaml
```

1. Указаны реквесты и лимиты подов, для которых они не заданы.
2. Минимальные и максимальные значения для подов (ограничение)

## Pod Security Policy
Запрет подключения подов с небезопасными параметрами (например, тома типа HotPath, которые раьотают от root и т.д.). Уже `depricated`. \
Сначала задаем политику, а поток включаем PSP, иначе кластер сломается (поды не будут создаваться).

# QA

1. __Как установить лимиты, чтобы не загурзить весь узел?__
Requests = limits. Еще, в kubelet есть ключики reservedCPU/reservedMemory, в которых задаются ресурсы узла, которые не отдаются kubernetes. 
2. __Как создать rootless контейнер?__
В докер-файле использовать другого user, не root. Но, вроде, в container runtime можно переопределить.
3. __Есть ли limit range на весь кластер?__
Нет, только в рамках namespace. 

