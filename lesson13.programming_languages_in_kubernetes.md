**Date** 11.11.2021
>> Continue 1:26:26

Frontend - скомпилировали статику и положили на nginx.

# Best Practices в docker

1. Multistage-сборки \
В рамках одного докер файла сначала собираем нужный бинарник (в неком базовом образе) -> потом запускаем новый числый базовый образ, где этот бинарник запускаем. 
```bash
# syntax=docker/dockerfile:1
FROM golang:1.16 AS builder
WORKDIR
Learn more about the "WORKDIR" Dockerfile command.
 /go/src/github.com/alexellis/href-counter/
RUN go get -d -v golang.org/x/net/html  
COPY app.go    ./
RUN CGO_ENABLED=0 GOOS=linux go build -a -installsuffix cgo -o app .

FROM alpine:latest  
RUN apk --no-cache add ca-certificates
WORKDIR /root/
COPY --from=builder /go/src/github.com/alexellis/href-counter/app ./
CMD ["./app"]  
```
2. Контейнеры запускаются не от root \
Директива `USER`. root имеет слишком много прав + уязвимости внутри контейнера (выйти на host, тоже в root). 

3. Один процесс = один контейнер. \
Если рассмотреть kubernetes как кластерную операционную системы - то контейнер = процесс. 

4. Не использовать версию latest или неявные версии образов. \
На в репозитрии в конвейере сборки могут быть другие версии, что приведет к проблемам в продуктиве, не эмилируемых локально.  

5. Не обновлять систему в контейнере (apt-get update). \
Каждый раз можем получить разный набор пакетов. 

6. Минимизация всего в контейнере. \
Не использовать большие ОС как базовые образы - ubuntu, centrOS. \
Зачем минимализируем образы: 
- снижаем риски атак,
- быстрее поднимаются при перезапуске,
- экономия места для хранения.
Количество слоев не имеет значения (предрассудок пошел от старой файловой системы overlayfs1, где поддерживались 20 слоев).

7. Если необходимо что-то использовать и удалить - писать в рамках одной инструкции `RUN`. \
Если писать в рамках нескольких, то каждая из них - это слой, поэтому размер образа не уменьшается при удалении + можно провалиться на нижлежащие слои и получить какую-то информацию. 
``` bash
# no
RUN 1
RUN 2
RUN 3
# yes 
RUN 1 && 2 && 3
```
Плюс не забывать удалять хэши пакетных менеджеров. 

8. Использовать внутреннее кэширование docker. \
```bash
COPY requirements.txt
RUN pip install -r requirements.txt  # download requirements
COPY . .  # copy all code
```
В этом примере зависимости (requirements) меняются редко, поэтому слои 1 и 2 будут просто пропускаться, а код часто - поэтому этот слой последний: изменение кода не приведет к пересборке всего проекта (скачиваю всех зависимостей)

9. Логирование. \
Обычный _старый_ подход - пишем в файлик, а потом уже что-то с ним делаем.
_Актуальный_ подход - пишем в stdout/stderr, и далее docker/podman или другой runtime что-то делает с логами (собираю, ротируют, размещают), а потом уже агенты собирают эти логи и куда-то отправляют.

10. Конфигурации. \
Не хардкодить, а получать из переменных окружения/конфиг файлов (configmap)

11. Приложению желательно обрабатывать сигнал на выключение - graceful shitdown. \
Если приходит sigterm, то завершить текущую задачу, и потом уже завершаться. 

# Java/C#

1. Использование application серверов (аплетов)
Кластер kubernetes уже по сути application сервер, поэтому специально запускать application сервер не нужно.

2. Выделение ресурсов для JVM
В Java до 8, приложение смотрело не на лимиты ресурсов, а на ресурсы доступные на ноде, поэтому быстро "выжирало" выделенное и падало. \
См. пример в репозитории от slerm - __13.programming-languages-in-kubernetes__

3. Параметр XMS и XMX
- XMS - оперативная память под heap изначально (рекомендация - 20% от лимита),
- XMX - максимальная оперативная память под heap (рекомендация - 40% лимита). 
Хорошая практика - выставлять/корректировать XMS/XMX в настройках JVM в соответствии с лимитами. Можно это автоматизировать через helm. 

4. Тяжеловестость процесса инициализации. 
- правильно выставлять liveness пробы (приложение просто может не успеть стартовать)
- большой объем ресурсов для старта, а в процессе работы потребность маленькая \
Если задать request = x, limit = 4x - риск того, что приезжая на ноду (по request), приложение может ее "убить" при старте, если там не хватает ресурсов для лимита. Решение: 
	- баланс между limit и допустимым временем ожидания запуска
	- отложененая инициализация (не поднимать все при старте)

# Интерпретируемые языки (python, ruby, php)

1. Распределение worker в application серверах.

Application server - нужен для интерпретации, выставляет количество воркеров для обработки запросов (исходя из количества CPU). _Проблема_ аналогичная java - смотрят не на лимиты, а на достпнуе ресурсы на ноде. 
*Best practice*: в контейнере - 1 процесс, а значит _1 воркер_. Масштабировать нужно унифицированно контейнеры, а не в конифгах каждый сервис.  

2. PYTHONUNBUFFERED - python буферизирует вывод и выводит логи частями, поэтому лучше установить отсутствие буферизации. 

# GoLang

Язык разработан для написания качественного и оптимизированного кода "не очень хорошими" разработчиками (а kubernetes - для "не очень хороших" админов). Идеально подходит для kubernetes.  \ 
Проблема с GOMAXPROCS, которое смотрит на количество ядер (лучше ставить = 1 или библиотека automaxproc). 

# QA

1. В докере не использовать apt-upgrade и apt-update? \
Apt-upgrade обновит хэши репозиториев, поэтому допустимо. Apt-update - обновляет пакеты, поэтому не нужно.

2. Как ухнать размер лимитов, находясь внутри контейнера? \
Где-то в директориях sys / proc. 
 
3. Как защититься от выполнения env в контейнере? \
Вероятнее всего, чтобы не посмотреть пароли в переменных. Не давать exec в файлы. Даже использоваться vault-операторов всегда посмотреть в processes. 

